{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"d1c48333-a03b-43da-8abd-de6d9a2b636e","_uuid":"4b07afc1-4525-43be-b534-3c79871f5bac","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:20:45.450014Z","iopub.status.busy":"2024-05-16T02:20:45.449592Z","iopub.status.idle":"2024-05-16T02:21:02.064344Z","shell.execute_reply":"2024-05-16T02:21:02.062484Z","shell.execute_reply.started":"2024-05-16T02:20:45.449984Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (4.40.2)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: filelock in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.0)\n","Requirement already satisfied: colorama in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (4.66.4)\n","Requirement already satisfied: colorama in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/cu121\n","Requirement already satisfied: torch==2.2.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (2.2.2+cu121)\n","Requirement already satisfied: torchvision==0.17.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (0.17.2+cu121)\n","Requirement already satisfied: torchaudio==2.2.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (2.2.2+cu121)\n","Requirement already satisfied: filelock in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (4.12.0)\n","Requirement already satisfied: sympy in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (1.12.1)\n","Requirement already satisfied: networkx in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (2024.5.0)\n","Requirement already satisfied: numpy in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torchvision==0.17.2) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torchvision==0.17.2) (10.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from jinja2->torch==2.2.2) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["%pip install transformers\n","%pip install tqdm\n","%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b98c07cf-e6d8-4a6b-b366-6c1f044b0d0c","_uuid":"aaf48f8b-867c-4f23-9810-266f280e3b9f","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:32:08.978825Z","iopub.status.busy":"2024-05-16T02:32:08.978374Z","iopub.status.idle":"2024-05-16T02:32:08.992603Z","shell.execute_reply":"2024-05-16T02:32:08.991272Z","shell.execute_reply.started":"2024-05-16T02:32:08.978795Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'query': 0, 'set': 1, 'update': 2}\n"]}],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","\n","# load csv\n","ds = pd.read_csv(\"datasets\\\\mod_class\\\\task_categories.csv\")\n","# get all unique categories\n","labels = sorted(set(ds[\"category\"]))\n","# enumerate labels because computers like numbers\n","labels_to_index = {label: idx for idx, label in enumerate(labels)}\n","print(labels_to_index)\n","# create a list of labels represented as numbers\n","# because the computer doesnt care about the text\n","ds[\"encoded_category\"] = [labels_to_index[label] for label in ds[\"category\"]]"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"aaf97f8f-bfd6-4082-9bff-6546be608b68","_uuid":"f03282b6-8aa5-4efa-9ae1-df826b9bc849","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:34:50.247322Z","iopub.status.busy":"2024-05-16T02:34:50.246874Z","iopub.status.idle":"2024-05-16T02:34:50.299008Z","shell.execute_reply":"2024-05-16T02:34:50.297851Z","shell.execute_reply.started":"2024-05-16T02:34:50.247293Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# now we need to split the data into training and \n","# validation sets for both the text and prompts\n","\n","# set a ratio to split the data\n","split_ratio = 0.8\n","total_samples = len(ds)\n","\n","# create a random set of indices from 0 to the \n","# total amount of samples in out data\n","indices = torch.randperm(total_samples)\n","\n","# using the indices split the indices into indices for\n","# training and validation\n","training_indices = indices[:int(total_samples * split_ratio)]\n","validation_indices = indices[int(total_samples * split_ratio):]\n","\n","# use the indices to select pieces of data to create\n","# the individual text and label sets for training\n","# and validation\n","training_texts = ds[\"text\"].iloc[training_indices]\n","training_labels = ds[\"encoded_category\"].iloc[training_indices]\n","validation_texts = ds[\"text\"].iloc[validation_indices]\n","validation_labels = ds[\"encoded_category\"].iloc[validation_indices]"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"3939bd74-bbaa-4b65-9685-2d15f429c0cd","_uuid":"4c5f9511-39e2-40e6-81ff-f7b59dc04bdc","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:36:54.240702Z","iopub.status.busy":"2024-05-16T02:36:54.240195Z","iopub.status.idle":"2024-05-16T02:36:58.411237Z","shell.execute_reply":"2024-05-16T02:36:58.410198Z","shell.execute_reply.started":"2024-05-16T02:36:54.240670Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\aidan\\Desktop\\random scripts\\Desktop Assistant\\AI-Desktop-Assistant\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\aidan\\Desktop\\random scripts\\Desktop Assistant\\AI-Desktop-Assistant\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["# we use the BertTokenizer to split up the text inputs \n","# into tokens which to help the computer draw relations\n","from transformers import BertTokenizer\n","\n","# load the tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# function to encode the text inputs\n","def encode_texts(texts):\n","    # padding going to add extra bits to the token \n","    # ensuring consistant length\n","    # truncation will remove bits from tokens \n","    # that are too long \n","    # return_tensors=\"pt\" will return a PyTorch tensor \n","    # which we like because tensors are efficient\n","    # to work with\n","    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# encode the training and validation texts\n","encoded_training_texts = encode_texts(training_texts.to_list())\n","encoded_validation_texts = encode_texts(validation_texts.to_list())"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"5f85fc7d-6ad8-4122-871d-55e78d6fd0a9","_uuid":"87b34fcc-4eff-4d04-8b28-05f19eab43de","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:48:16.952164Z","iopub.status.busy":"2024-05-16T02:48:16.951714Z","iopub.status.idle":"2024-05-16T02:48:16.960844Z","shell.execute_reply":"2024-05-16T02:48:16.959486Z","shell.execute_reply.started":"2024-05-16T02:48:16.952132Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# now we need to create our training and validation  \n","# datasets using TensorDatasets which i think tensors are\n","# good because its an indiscriminant numerical way of \n","# interpreting data\n","from torch.utils.data import DataLoader,TensorDataset\n","\n","# we neeed to create Tensor datasets for \n","# our training and validation sets\n","training_dataset = TensorDataset(encoded_training_texts[\"input_ids\"], encoded_training_texts[\"attention_mask\"], torch.tensor(training_labels.to_list()))\n","validation_dataset = TensorDataset(encoded_validation_texts[\"input_ids\"], encoded_validation_texts[\"attention_mask\"], torch.tensor(validation_labels.to_list()))\n","\n","# with our datasets now we need to create Dataloaders to\n","# to be able to load our data for processing\n","\n","# this will be the number of samples \n","# used in one iteration of training\n","sampling_size = 16\n","training_loader = DataLoader(training_dataset, batch_size=sampling_size, shuffle=True)\n","validation_loader = DataLoader(validation_dataset, batch_size=sampling_size)"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"c8228fff-fbbe-4cb5-b16d-06d29bf3e67d","_uuid":"9816f062-f86d-4c8e-bc7c-d476637aa964","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T02:56:42.906444Z","iopub.status.busy":"2024-05-16T02:56:42.905975Z","iopub.status.idle":"2024-05-16T02:56:46.902972Z","shell.execute_reply":"2024-05-16T02:56:46.899883Z","shell.execute_reply.started":"2024-05-16T02:56:42.906409Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\aidan\\Desktop\\random scripts\\Desktop Assistant\\AI-Desktop-Assistant\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# To start training we need to load in a pre-trained \n","# model, with Bert there is a pre-trained model good \n","# for text classification\n","from transformers import BertForSequenceClassification\n","import torch.optim as optim\n","# define the amount of unique labels for the model\n","num_unique_labels = len(labels)\n","\n","# load the model\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_unique_labels)\n","\n","# here we want to decide what hardware we are \n","# using to train our model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# now lets move the model to the selected hardware\n","model = model.to(device)\n","\n","# now we need to define the optimization \n","# and loss functions\n","learning_rate = 2e-5\n","# the optimization function adjusts the models \n","# parameters to improve its performance\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","# CrossEntropyLoss is a loss function that is good\n","# for text classification\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"5562b87e-f95a-4d02-88e0-6ecf0a9c5331","_uuid":"b8b58ff7-128f-4783-860c-e12c9455c632","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T03:00:32.335243Z","iopub.status.busy":"2024-05-16T03:00:32.333796Z","iopub.status.idle":"2024-05-16T03:07:04.737458Z","shell.execute_reply":"2024-05-16T03:07:04.736319Z","shell.execute_reply.started":"2024-05-16T03:00:32.335205Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:02<00:00,  3.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 1.1011453419923782\n","Training Loss: 1.1011, Training Accuracy: 56.61%\n","Validation Loss: 1.0081, Validation Accuracy: 77.50%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  7.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 0.9461124464869499\n","Training Loss: 0.9461, Training Accuracy: 84.91%\n","Validation Loss: 0.8392, Validation Accuracy: 83.33%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  7.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 0.7085143551230431\n","Training Loss: 0.7085, Training Accuracy: 92.91%\n","Validation Loss: 0.5501, Validation Accuracy: 81.67%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  6.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 0.41355044580996037\n","Training Loss: 0.4136, Training Accuracy: 97.24%\n","Validation Loss: 0.3291, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:00<00:00,  8.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 0.2091422462835908\n","Training Loss: 0.2091, Training Accuracy: 98.86%\n","Validation Loss: 0.1490, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  6.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 0.0962586784735322\n","Training Loss: 0.0963, Training Accuracy: 100.00%\n","Validation Loss: 0.0911, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  6.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 0.05160977132618427\n","Training Loss: 0.0516, Training Accuracy: 100.00%\n","Validation Loss: 0.0548, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:01<00:00,  7.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 0.030897559830918908\n","Training Loss: 0.0309, Training Accuracy: 100.00%\n","Validation Loss: 0.0456, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:00<00:00,  8.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 0.021812433609738946\n","Training Loss: 0.0218, Training Accuracy: 100.00%\n","Validation Loss: 0.0384, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:00<00:00,  8.50it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.016221774276345968\n","Training Loss: 0.0162, Training Accuracy: 100.00%\n","Validation Loss: 0.0330, Validation Accuracy: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def calculate_accuracy(logits, labels):\n","    # Convert logits to predicted class by taking the index of the maximum value in logits (argmax)\n","    predictions = torch.argmax(logits, dim=-1)\n","    # We need to ignore padding in the labels for accuracy calculation\n","    # Assuming padding token ID is 0 (or another specific ID depending on the tokenizer)\n","    mask = labels != tokenizer.pad_token_id  # tokenizer should be defined elsewhere and have pad_token_id attribute\n","\n","    # Only consider non-padded elements for accuracy calculation\n","    correct_predictions = (predictions == labels) & mask  # Logical AND to ignore padded elements\n","    total_correct_tokens = correct_predictions.float().sum()  # Sum up the number of correct tokens\n","    total_non_padded_tokens = mask.float().sum()  # Sum up the number of non-padded tokens\n","    \n","    # Calculate the mean of correct predictions\n","    if total_non_padded_tokens > 0:\n","        accuracy = 100 * total_correct_tokens / total_non_padded_tokens\n","    else:\n","        accuracy = 0.0  # Avoid division by zero if there are no non-padded tokens\n","    return accuracy.item()\n","\n","def validation(avg_training_loss, avg_training_accuracy):\n","    model.eval()\n","    total_validation_loss = 0\n","    total_validation_accuracy = 0\n","    with torch.no_grad():\n","        for batch in validation_loader:\n","            \n","            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            \n","            total_validation_loss += loss.item()\n","            total_validation_accuracy += calculate_accuracy(outputs.logits, labels)\n","            \n","        avg_validation_loss = total_validation_loss / len(validation_loader)\n","        avg_validation_accuracy = total_validation_accuracy / len(validation_loader)\n","        \n","        print(f'Training Loss: {avg_training_loss:.4f}, Training Accuracy: {avg_training_accuracy:.2f}%')\n","        print(f'Validation Loss: {avg_validation_loss:.4f}, Validation Accuracy: {avg_validation_accuracy:.2f}%')\n","\n","        \n","# After:\n","# Converting labels to indices for the computer \n","# to understand\n","# Selecting labels(as indices) and texts for training and\n","# validation\n","# Tokenizing our texts to allow the computer to draw\n","# relations in our data better\n","# Creating our TensorDatasets for the computer to\n","# better understand our data as well as DataLoaders\n","# Setting up our training environment\n","\n","# we can now set up our training loop\n","\n","# we can use tqdm to get a nice tqdm to visualize progress\n","from tqdm import tqdm\n","\n","# define the number of epochs\n","num_epochs = 10\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    total_accuracy = 0\n","    for batch in tqdm(training_loader):\n","        # we need to move our training batch to the same\n","        # hardware as the model\n","        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","        \n","        # We need to clear gradients from previous epochs\n","        optimizer.zero_grad()\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        total_accuracy += calculate_accuracy(outputs.logits, labels)\n","                                             \n","    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(training_loader)}\")\n","    avg_training_loss = total_loss / len(training_loader)\n","    avg_training_accuracy = total_accuracy / len(training_loader)\n","    validation(avg_training_loss, avg_training_accuracy)"]},{"cell_type":"code","execution_count":51,"metadata":{"_cell_guid":"3362aba1-8aeb-4666-85fb-9209e50e8156","_uuid":"5fceb480-1ad7-489b-9cdf-52494cf614c9","collapsed":false,"execution":{"iopub.execute_input":"2024-05-16T03:47:05.681009Z","iopub.status.busy":"2024-05-16T03:47:05.680581Z","iopub.status.idle":"2024-05-16T03:47:25.741940Z","shell.execute_reply":"2024-05-16T03:47:25.740752Z","shell.execute_reply.started":"2024-05-16T03:47:05.680980Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Label: query, Confidence: 0.98\n"]}],"source":["# import this torch functional library and use softmax to convert\n","# logits to probabilites to get a confidence in a precentage\n","import torch.nn.functional as f\n","# Function to take text input and pass to model\n","def predict(text):\n","    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","    input_ids = encoded_input[\"input_ids\"].to(device)\n","    attention_mask = encoded_input[\"attention_mask\"].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","    \n","    logits = outputs.logits\n","    probs = f.softmax(logits, dim=1)\n","    \n","    predicted_label_id = torch.argmax(probs,dim=1).item()\n","    confidence = probs[0][predicted_label_id].item()\n","    predicted_label = \"\"\n","    for label, idx in labels_to_index.items():\n","        if predicted_label_id == idx:\n","            predicted_label = label\n","    return predicted_label, confidence\n","\n","predicted_label, confidence = predict(input(\"Prompt: \"))\n","print(f\"Predicted Label: {predicted_label}, Confidence: {confidence:.2f}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"eb4b6947-d323-4e9d-974c-6cdf77fc19f2","_uuid":"46796a78-0e60-476c-83f5-47b9c1f6ac9d","collapsed":false,"execution":{"iopub.execute_input":"2024-05-14T00:26:05.353273Z","iopub.status.busy":"2024-05-14T00:26:05.352332Z","iopub.status.idle":"2024-05-14T00:26:06.386431Z","shell.execute_reply":"2024-05-14T00:26:06.384876Z","shell.execute_reply.started":"2024-05-14T00:26:05.353241Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Assuming `model` is your trained model\n","torch.save(model, 'task_req_classification_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5207e9b1-3e71-4ddc-949e-2b5c6e4e3929","_uuid":"97c34924-a462-4b28-90ae-cb9fe2b381bc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5000000,"sourceId":8403008,"sourceType":"datasetVersion"},{"datasetId":5001065,"sourceId":8404484,"sourceType":"datasetVersion"},{"datasetId":5001368,"sourceId":8404905,"sourceType":"datasetVersion"},{"datasetId":5001573,"sourceId":8405196,"sourceType":"datasetVersion"},{"datasetId":5001601,"sourceId":8405243,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
