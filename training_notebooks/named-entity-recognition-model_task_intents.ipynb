{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (4.40.2)\n","Requirement already satisfied: filelock in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.0)\n","Requirement already satisfied: colorama in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (4.66.4)\n","Requirement already satisfied: colorama in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/cu121\n","Requirement already satisfied: torch==2.2.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (2.2.2+cu121)\n","Requirement already satisfied: torchvision==0.17.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (0.17.2+cu121)\n","Requirement already satisfied: torchaudio==2.2.2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (2.2.2+cu121)\n","Requirement already satisfied: filelock in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (4.12.0)\n","Requirement already satisfied: sympy in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (1.12.1)\n","Requirement already satisfied: networkx in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torch==2.2.2) (2024.5.0)\n","Requirement already satisfied: numpy in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torchvision==0.17.2) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from torchvision==0.17.2) (10.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from jinja2->torch==2.2.2) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\aidan\\desktop\\random scripts\\desktop assistant\\ai-desktop-assistant\\.venv\\lib\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["%pip install transformers\n","%pip install tqdm\n","%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121"]},{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-16T18:22:53.887287Z","iopub.status.busy":"2024-05-16T18:22:53.886772Z","iopub.status.idle":"2024-05-16T18:22:53.899316Z","shell.execute_reply":"2024-05-16T18:22:53.897708Z","shell.execute_reply.started":"2024-05-16T18:22:53.887246Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n","import json\n","from tqdm import tqdm\n","\n","with open('datasets\\\\ner\\\\task_intents.json') as f:\n","    ds = json.load(f)\n","\n","labels_to_index = {\"O\": 0, \"INTENT\": 1}\n","texts = []\n","labels = []\n","encoded_labels = []\n","# create a list of labels represented as numbers\n","# because the computer doesnt care about the text\n","assert len(texts) == len(labels), \"Mismatch between number of sentences and labels\"\n","for item in ds:\n","    texts.append(item[\"sentence\"])\n","    labels.append(item[\"labels\"])\n","    assert len(item[\"sentence\"].split()) == len(item[\"labels\"]), f\"Mismatch in length for sentence: {item}\"\n","    encoded_labels.append([labels_to_index[label] for label in item[\"labels\"]])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T18:29:01.909132Z","iopub.status.busy":"2024-05-16T18:29:01.908652Z","iopub.status.idle":"2024-05-16T18:29:01.918210Z","shell.execute_reply":"2024-05-16T18:29:01.917002Z","shell.execute_reply.started":"2024-05-16T18:29:01.909097Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['Mark', 'assemble', 'the', 'new', 'desk', 'as', 'done', 'on', 'my', 'task', 'list'], ['can', 'you', 'schedule', 'a', 'task', 'for', 'tomorrow', 'at', '8'], ['what', 'tasks', 'do', 'i', 'have', 'to', 'do', 'today'], ['set', 'a', 'reminder', 'to', 'go', 'for', 'a', 'run', 'at', '6', 'AM'], ['Done', 'with', 'the', 'car', 'service', 'can', 'you', 'update', 'my', 'tasks?'], ['what', 'are', 'my', 'tasks', 'for', 'today'], ['mark', 'that', \"I've\", 'backed', 'up', 'all', 'critical', 'data', 'this', 'month', 'as', 'complete'], ['Do', 'I', 'have', 'any', 'reminders', 'to', 'call', 'suppliers', 'this', 'week'], ['I', 'have', 'completed', 'the', 'meal', 'prep', 'for', 'this', 'week', 'mark', 'it', 'complete'], ['Change', 'the', 'reminder', 'for', 'vet', 'visit', 'to', 'the', 'first', 'Monday', 'of', 'every', 'month'], ['Can', 'you', 'update', 'the', 'reminder', 'for', 'the', \"doctor's\", 'appointment', 'to', 'next', 'Wednesday', 'at', '3', 'PM'], ['would', 'you', 'mind', 'reminding', 'me', 'to', 'pick', 'up', 'the', 'dry', 'cleaning'], ['can', 'you', 'remind', 'me', 'to', 'go', 'to', 'bed', 'in', '2', 'hours'], ['mark', 'my', 'last', 'task', 'as', 'complete'], ['what', 'are', 'my', 'upcoming', 'tasks'], ['What', 'time', 'is', 'my', 'weekly', 'team', 'update'], ['add', 'a', 'meeting', 'at', 'noon'], ['what', 'are', 'my', 'upcoming', 'tasks'], ['add', 'write', 'a', 'blog', 'post', 'to', 'my', 'to-do', 'list'], ['what', 'are', 'the', 'tasks', 'i', 'have', 'today'], ['add', 'yoga', 'class', 'to', 'my', 'monday', 'routine'], ['could', 'you', 'set', 'a', 'reminder', 'to', 'call', 'the', 'bank'], ['do', 'i', 'have', 'any', 'tasks', 'later'], ['remind', 'me', 'to', 'buy', 'groceries', 'tomorrow'], ['Show', 'me', 'the', 'reminders', 'for', 'the', 'kids', 'school', 'events', 'this', 'month'], ['when', 'am', 'i', 'scheduled', 'to', 'meet', 'with', 'my', 'realtor'], ['Adjust', 'the', 'time', 'for', 'my', 'daily', 'workout', 'reminder', 'to', '7', 'AM', 'instead', 'of', '6', 'AM'], ['would', 'you', 'be', 'able', 'to', 'set', 'a', 'reminder', 'for', 'my', 'annual', 'checkup'], ['Do', 'I', 'have', 'any', 'reminders', 'set', 'for', 'veterinary', 'appointments'], ['create', 'a', 'task', 'to', 'update', 'my', 'resume'], ['would', 'you', 'be', 'able', 'to', 'set', 'a', 'task', 'for', '5', 'pm'], ['what', 'tasks', 'do', 'i', 'have', 'today'], ['what', 'are', 'my', 'tasks', 'for', 'today'], ['what', 'tasks', 'do', 'i', 'have', 'for', 'tomorrow'], ['add', 'plan', 'the', 'birthday', 'party', 'to', 'my', 'tasks'], ['remind', 'me', 'to', 'water', 'the', 'plants', 'every', 'monday'], ['when', 'is', 'my', 'next', 'reservation', 'for', 'maestros', 'dinner'], ['Are', 'there', 'any', 'reminders', 'set', 'for', 'my', 'anniversary'], ['Can', 'you', 'list', 'the', 'reminders', 'I', 'have', 'for', 'car', 'maintenance'], ['create', 'a', 'task', 'to', 'finish', 'reading', 'the', 'book'], ['could', 'you', 'remind', 'me', 'to', 'call', 'mom', 'at', '5', 'pm'], ['set', 'a', 'reminder', 'to', 'go', 'for', 'a', 'run', 'at', '6', 'AM'], ['remind', 'me', 'to', 'call', 'mom', 'at', '5', 'pm'], ['Mark', 'the', 'task', 'write', 'the', 'weekly', 'newsletter', 'as', 'complete'], ['Modify', 'the', 'reminder', 'to', 'review', 'the', 'budget', 'reports', 'to', 'the', 'last', 'Friday', 'of', 'each', 'month'], ['add', 'write', 'a', 'blog', 'post', 'to', 'my', 'to-do', 'list'], ['remind', 'me', 'to', 'buy', 'groceries', 'tomorrow'], ['Check', 'off', 'organize', 'the', 'garage', 'from', 'my', 'to', 'do', 'list'], ['add', 'plan', 'the', 'birthday', 'party', 'to', 'my', 'tasks'], ['would', 'you', 'mind', 'setting', 'a', 'reminder', 'to', 'exercise', 'at', '7', 'pm'], ['Please', 'change', 'the', 'alarm', 'for', 'morning', 'yoga', 'from', '6:30', 'AM', 'to', '7:15', 'AM'], ['Change', 'the', 'reminder', 'for', 'vet', 'visit', 'to', 'the', 'first', 'Monday', 'of', 'every', 'month'], ['add', 'plan', 'the', 'vacation', 'to', 'my', 'tasks'], ['set', 'a', 'reminder', 'to', 'visit', 'grandma', 'on', 'sunday'], ['can', 'you', 'remind', 'me', 'to', 'call', 'john', 'in', '20', 'minutes'], ['Check', 'off', 'arrange', 'the', 'client', 'portfolio'], ['do', 'i', 'have', 'anything', 'to', 'be', 'reminded', 'about', 'today'], ['mark', 'the', 'laundry', 'task', 'as', 'completed'], ['Can', 'you', 'show', 'me', 'my', 'tasks', 'related', 'to', 'the', 'home', 'renovation', 'project'], ['Finalize', 'the', 'task', 'of', 'calling', 'the', 'plumber'], ['add', 'organize', 'my', 'desk', 'to', 'my', 'tasks'], ['Can', 'you', 'tell', 'me', 'what', 'my', 'reminders', 'for', 'next', 'week', 'are'], ['mark', 'the', 'grocery', 'shopping', 'task', 'as', 'completed'], ['Show', 'me', 'the', 'reminders', 'for', 'the', 'kids', 'school', 'events', 'this', 'month'], ['can', 'you', 'schedule', 'a', 'task', 'for', 'tomorrow', 'at', '8'], ['when', 'is', 'my', 'next', 'doctors', 'appointment'], ['mark', 'that', \"I've\", 'backed', 'up', 'all', 'critical', 'data', 'this', 'month', 'as', 'complete'], ['What', 'are', 'my', 'reminders', 'for', 'taking', 'medication'], ['would', 'you', 'be', 'able', 'to', 'set', 'a', 'task', 'for', '5', 'pm'], ['Mark', 'assemble', 'the', 'new', 'desk', 'as', 'done', 'on', 'my', 'task', 'list'], ['mark', 'my', 'last', 'task', 'as', 'complete'], ['Do', 'I', 'have', 'reminders', 'set', 'for', 'any', 'upcoming', 'holidays'], ['Do', 'I', 'have', 'any', 'reminders', 'set', 'for', 'veterinary', 'appointments'], ['can', 'you', 'remind', 'me', 'to', 'go', 'to', 'bed', 'in', '2', 'hours'], ['Just', 'mowed', 'the', 'lawn', 'can', 'you', 'check', 'that', 'off'], ['Are', 'there', 'any', 'reminders', 'to', 'check', 'on', 'the', 'house', 'renovation', 'progress'], ['could', 'you', 'create', 'a', 'task', 'to', 'clean', 'the', 'house', 'in', '2', 'hours'], ['Mark', 'the', 'schedule', 'dentist', 'appointment', 'task', 'as', 'complete'], ['can', 'you', 'remind', 'me', 'to', 'water', 'the', 'plants', 'every', 'monday'], ['schedule', 'an', 'office', 'visit', 'for', 'next', 'friday'], ['can', 'you', 'add', 'paint', 'the', 'living', 'room', 'to', 'my', 'to-do', 'list'], ['Done', 'with', 'the', 'software', 'upgrade', 'can', 'you', 'update', 'my', 'tasks'], ['set', 'a', 'reminder', 'to', 'visit', 'grandma', 'on', 'sunday'], ['I', 'have', 'paid', 'the', 'utility', 'bills', 'please', 'check', 'that', 'off'], ['what', 'are', 'my', 'next', '3', 'tasks'], ['put', 'a', 'car', 'service', 'on', 'my', 'schedule', 'for', 'friday'], ['remind', 'me', 'to', 'water', 'the', 'plants', 'every', 'monday'], ['remind', 'me', 'to', 'call', 'john', 'in', '5', 'hours'], ['remind', 'me', 'to', 'pay', 'the', 'electricity', 'bill'], ['How', 'many', 'tasks', 'are', 'scheduled', 'for', 'this', 'weekend'], ['Update', 'my', 'reminder', 'to', 'call', 'mom', 'to', 'every', 'Sunday', 'at', '4', 'PM'], ['Can', 'you', 'show', 'me', 'my', 'tasks', 'related', 'to', 'the', 'home', 'renovation', 'project'], ['Finalize', 'the', 'task', 'of', 'redecorating', 'the', 'office', 'lobby', 'and', 'mark', 'it', 'complete'], ['can', 'you', 'remind', 'me', 'to', 'review', 'the', 'contract'], ['What', 'reminders', 'do', 'I', 'have', 'set', 'for', 'my', 'yoga', 'classes'], ['what', 'is', 'my', 'next', 'reminder'], ['set', 'a', 'reminder', 'to', 'meditate', 'daily'], ['what', 'tasks', 'do', 'i', 'have', 'to', 'do', 'today'], ['would', 'you', 'be', 'able', 'to', 'create', 'a', 'task', 'to', 'finish', 'the', 'project', 'report'], ['add', 'buy', 'groceries', 'to', 'my', 'to-do', 'list'], ['add', 'buy', 'a', 'new', 'phone', 'to', 'my', 'to-do', 'list'], ['What', 'reminders', 'do', 'I', 'have', 'set', 'for', 'my', 'yoga', 'classes'], ['add', 'plan', 'the', 'vacation', 'to', 'my', 'tasks'], ['What', 'reminders', 'do', 'I', 'have', 'about', 'project', 'deadlines'], ['set', 'a', 'reminder', 'for', 'my', 'dentist', 'appointment'], ['Are', 'there', 'any', 'reminders', 'set', 'for', 'my', 'anniversary'], ['Update', 'my', 'reminder', 'to', 'call', 'mom', 'to', 'every', 'Sunday', 'at', '4', 'PM'], ['Check', 'off', 'prepare', 'the', 'guest', 'room'], ['Change', 'the', 'reminder', 'for', 'vet', 'visit', 'to', 'the', 'first', 'Monday', 'of', 'every', 'month'], ['what', 'is', 'my', 'next', 'reminder'], ['add', 'schedule', 'a', 'meeting', 'with', 'the', 'team', 'to', 'my', 'todo', 'list'], ['Can', 'you', 'show', 'me', 'my', 'tasks', 'related', 'to', 'the', 'home', 'renovation', 'project'], ['would', 'you', 'be', 'able', 'to', 'set', 'a', 'reminder', 'for', 'my', 'annual', 'checkup'], ['could', 'you', 'create', 'a', 'task', 'to', 'backup', 'my', 'computer'], ['how', 'many', 'tasks', 'do', 'i', 'have', 'today'], [\"what's\", 'the', 'next', 'task', 'i', 'have'], ['add', 'send', 'birthday', 'card', 'to', 'my', 'tasks'], ['set', 'an', 'alarm', 'for', '7', 'am', 'tomorrow'], ['remind', 'me', 'to', 'review', 'the', 'contract'], ['add', 'a', 'meeting', 'at', 'noon'], ['can', 'you', 'add', 'fix', 'the', 'leaking', 'faucet', 'to', 'my', 'tasks'], ['Can', 'you', 'list', 'the', 'reminders', 'I', 'have', 'for', 'car', 'maintenance'], ['mark', 'the', 'laundry', 'task', 'as', 'completed'], ['remind', 'me', 'to', 'call', 'mom', 'at', '5', 'pm'], ['create', 'a', 'task', 'to', 'finish', 'reading', 'the', 'book'], ['Mark', 'the', 'schedule', 'dentist', 'appointment', 'task', 'as', 'complete'], ['set', 'a', 'reminder', 'for', 'my', 'anniversary', 'in', '4', 'weeks'], ['can', 'you', 'remind', 'me', 'to', 'pay', 'the', 'electricity', 'bill'], [\"I've\", 'completed', 'the', 'performance', 'reviews', 'please', 'check', 'that', 'off'], ['put', 'a', 'car', 'service', 'on', 'my', 'schedule', 'for', 'friday'], ['would', 'you', 'be', 'able', 'to', 'remind', 'me', 'to', 'check', 'the', 'tire', 'pressure', 'monthly'], ['do', 'i', 'have', 'anything', 'to', 'be', 'reminded', 'about', 'today'], ['What', 'reminders', 'do', 'I', 'have', 'set', 'for', 'my', 'yoga', 'classes'], ['Change', 'the', 'reminder', 'for', 'vet', 'visit', 'to', 'the', 'first', 'Monday', 'of', 'every', 'month'], ['Please', 'change', 'the', 'alarm', 'for', 'morning', 'yoga', 'from', '6:30', 'AM', 'to', '7:15', 'AM'], ['create', 'a', 'task', 'to', 'design', 'the', 'new', 'logo'], ['Move', 'the', 'reminder', 'for', 'taking', 'out', 'the', 'trash', 'to', 'Sunday', 'evening'], ['Check', 'off', 'organize', 'the', 'garage', 'from', 'my', 'to', 'do', 'list'], ['Can', 'you', 'update', 'the', 'reminder', 'for', 'the', \"doctor's\", 'appointment', 'to', 'next', 'Wednesday', 'at', '3', 'PM'], ['what', 'reminders', 'do', 'i', 'have', 'for', 'tomorrow'], ['create', 'a', 'task', 'to', 'design', 'the', 'new', 'logo'], ['Are', 'there', 'any', 'reminders', 'for', 'meetings', 'with', 'clients', 'next', 'Tuesday'], ['Do', 'I', 'have', 'any', 'reminders', 'to', 'call', 'suppliers', 'this', 'week'], ['create', 'a', 'task', 'to', 'call', 'the', 'electrician'], ['What', 'do', 'I', 'need', 'to', 'remember', 'for', 'this', 'weekend'], ['Confirm', 'that', \"I've\", 'attended', 'the', 'team', 'meeting'], ['Complete', 'the', 'task', 'for', 'booking', 'the', 'flight', 'tickets'], ['can', 'you', 'set', 'a', 'reminder', 'to', 'check', 'the', 'mail'], ['would', 'you', 'mind', 'creating', 'a', 'task', 'to', 'review', 'the', 'budget'], ['add', 'book', 'flight', 'tickets', 'to', 'my', 'to-do', 'list'], ['remind', 'me', 'to', 'take', 'out', 'the', 'trash', 'at', '5'], ['Finalize', 'the', 'task', 'of', 'redecorating', 'the', 'office', 'lobby', 'and', 'mark', 'it', 'complete'], ['Check', 'off', 'prepare', 'the', 'guest', 'room'], ['schedule', 'a', 'dentist', 'appointment', 'next', 'wednesday'], ['Can', 'you', 'tell', 'me', 'what', 'my', 'reminders', 'for', 'next', 'week', 'are'], ['can', 'you', 'remind', 'me', 'to', 'pay', 'the', 'rent', 'on', 'the', 'first'], ['what', 'are', 'the', 'tasks', 'i', 'have', 'today'], ['remind', 'me', 'to', 'call', 'john', 'in', '5', 'hours'], ['remind', 'me', 'to', 'send', 'the', 'report', 'every', 'friday'], ['remind', 'me', 'to', 'pay', 'the', 'electricity', 'bill'], ['remind', 'me', 'to', 'pay', 'the', 'rent', 'on', 'the', 'first'], ['would', 'you', 'mind', 'reminding', 'me', 'to', 'pick', 'up', 'the', 'dry', 'cleaning'], ['can', 'you', 'set', 'a', 'reminder', 'to', 'check', 'the', 'mail'], ['do', 'i', 'have', 'any', 'tasks', 'coming', 'up', 'later'], ['add', 'send', 'birthday', 'card', 'to', 'my', 'tasks'], ['Mark', 'the', 'task', 'write', 'the', 'weekly', 'newsletter', 'as', 'complete'], ['add', 'book', 'flight', 'tickets', 'to', 'my', 'to-do', 'list'], ['Can', 'you', 'show', 'me', 'the', 'tasks', 'I', 'have', 'due', 'for', 'the', 'marketing', 'campaign'], ['would', 'you', 'be', 'able', 'to', 'remind', 'me', 'to', 'check', 'the', 'tire', 'pressure', 'monthly'], ['Are', 'there', 'any', 'reminders', 'to', 'renew', 'subscriptions', 'or', 'memberships'], ['Complete', 'the', 'task', 'for', 'booking', 'the', 'flight', 'tickets'], ['Check', 'off', 'grocery', 'shopping', 'from', 'my', 'task', 'list'], ['schedule', 'an', 'office', 'visit', 'for', 'next', 'friday'], ['remind', 'me', 'to', 'pay', 'the', 'rent', 'on', 'the', 'first'], ['Complete', 'the', 'task', 'for', 'booking', 'the', 'flight', 'tickets'], ['Done', 'with', 'sending', 'the', 'emails', 'can', 'you', 'mark', 'that', 'complete'], ['Are', 'there', 'any', 'reminders', 'for', 'meetings', 'with', 'clients', 'next', 'Tuesday'], ['What', 'reminders', 'do', 'I', 'have', 'set', 'for', 'my', 'yoga', 'classes'], ['when', 'am', 'i', 'scheduled', 'to', 'meet', 'with', 'my', 'real', 'estate', 'agent'], ['can', 'you', 'add', 'clean', 'the', 'garage', 'to', 'my', 'tasks'], ['can', 'you', 'remind', 'me', 'to', 'go', 'for', 'a', 'checkup', 'in', '2', 'hours'], ['do', 'i', 'have', 'any', 'tasks', 'later'], ['can', 'you', 'remind', 'me', 'to', 'water', 'the', 'plants', 'every', 'monday'], ['Done', 'with', 'the', 'software', 'upgrade', 'can', 'you', 'update', 'my', 'tasks'], ['Are', 'there', 'any', 'reminders', 'to', 'check', 'on', 'the', 'house', 'renovation', 'progress'], ['Update', 'my', 'reminder', 'to', 'call', 'mom', 'to', 'every', 'Sunday', 'at', '4', 'PM'], ['could', 'you', 'set', 'a', 'reminder', 'to', 'call', 'the', 'bank'], ['I', 'have', 'completed', 'the', 'meal', 'prep', 'for', 'this', 'week', 'mark', 'it', 'complete'], ['remind', 'me', 'to', 'review', 'the', 'contract'], ['mark', 'the', 'grocery', 'shopping', 'task', 'as', 'completed'], ['Modify', 'the', 'reminder', 'to', 'review', 'the', 'budget', 'reports', 'to', 'the', 'last', 'Friday', 'of', 'each', 'month'], ['What', 'reminders', 'do', 'I', 'have', 'about', 'project', 'deadlines'], ['Can', 'you', 'reschedule', 'the', 'reminder', 'for', 'the', 'project', 'deadline', 'to', 'two', 'days', 'earlier'], ['would', 'you', 'mind', 'setting', 'a', 'reminder', 'to', 'exercise', 'at', '7', 'pm'], ['when', 'am', 'i', 'scheduled', 'to', 'meet', 'with', 'my', 'real', 'estate', 'agent'], ['add', 'organize', 'my', 'desk', 'to', 'my', 'tasks'], ['can', 'you', 'add', 'clean', 'the', 'garage', 'to', 'my', 'tasks'], ['what', 'tasks', 'do', 'i', 'have', 'for', 'tomorrow'], ['set', 'a', 'reminder', 'for', 'my', 'anniversary', 'in', '4', 'weeks'], ['schedule', 'a', 'date', 'night', 'in', '3', 'weeks'], ['can', 'you', 'remind', 'me', 'to', 'send', 'the', 'report', 'every', 'friday'], ['add', 'schedule', 'a', 'meeting', 'with', 'the', 'team', 'to', 'my', 'todo', 'list'], [\"I've\", 'finished', 'drafting', 'the', 'agreement', 'check', 'it', 'off', 'my', 'list'], ['can', 'you', 'remind', 'me', 'to', 'send', 'the', 'report', 'every', 'friday'], ['can', 'you', 'remind', 'me', 'to', 'review', 'the', 'contract'], ['can', 'you', 'remind', 'me', 'in', '3', 'hours', 'to', 'buy', 'groceries'], ['Check', 'off', 'arrange', 'the', 'client', 'portfolio'], ['Change', 'my', 'reminder', 'for', 'the', 'team', 'meeting', 'from', '10', 'AM', 'to', '11', 'AM', 'tomorrow'], ['create', 'a', 'task', 'to', 'update', 'my', 'resume'], ['create', 'a', 'task', 'to', 'call', 'the', 'electrician'], ['schedule', 'a', 'date', 'night', 'in', '3', 'weeks'], ['What', 'are', 'my', 'reminders', 'for', 'taking', 'medication'], [\"I've\", 'completed', 'the', 'performance', 'reviews', 'please', 'check', 'that', 'off'], [\"what's\", 'the', 'next', 'task', 'i', 'have'], ['what', 'time', 'do', 'i', 'have', 'to', 'be', 'at', 'my', 'moms', 'birthday'], ['set', 'a', 'reminder', 'for', 'my', 'dentist', 'appointment']]\n","[[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1], [0, 0, 1, 0, 0], [0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 1, 1, 0, 0, 0, 0], [0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1], [0, 0, 1, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 1, 1]]\n"]}],"source":["# now we need to split the data into training and \n","# validation sets for both the text and prompts\n","\n","# set a ratio to split the data\n","split_ratio = 0.8\n","total_samples = len(ds)\n","\n","# create a random set of indices from 0 to the \n","# total amount of samples in out data\n","indices = torch.randperm(total_samples)\n","\n","# using the indices split the indices into indices for\n","# training and validation\n","training_indices = indices[:int(total_samples * split_ratio)]\n","validation_indices = indices[int(total_samples * split_ratio):]\n","\n","# use the indices to select pieces of data to create\n","# the individual text and label sets for training\n","# and validation\n","training_texts = [texts[idx].split() for idx in training_indices]\n","encoded_training_labels = [encoded_labels[idx] for idx in training_indices]\n","validation_texts = [texts[idx].split() for idx in validation_indices]\n","encoded_validation_labels = [encoded_labels[idx] for idx in validation_indices]\n","print(training_texts)\n","print(encoded_training_labels)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T18:29:03.230270Z","iopub.status.busy":"2024-05-16T18:29:03.229832Z","iopub.status.idle":"2024-05-16T18:29:03.530623Z","shell.execute_reply":"2024-05-16T18:29:03.528913Z","shell.execute_reply.started":"2024-05-16T18:29:03.230236Z"},"trusted":true},"outputs":[],"source":["# load the tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","# function to encode the text inputs\n","def encode_texts(texts):\n","    # padding going to add extra bits to the token \n","    # ensuring consistant length\n","    # truncation will remove bits from tokens \n","    # that are too long \n","    # return_tensors=\"pt\" will return a PyTorch tensor \n","    # which we like because tensors are efficient\n","    # to work with\n","    return tokenizer(texts, truncation=True, padding='max_length', is_split_into_words=True, return_tensors=\"pt\")\n","\n","# encode the training and validation texts\n","encoded_training_texts = encode_texts(training_texts)\n","encoded_validation_texts = encode_texts(validation_texts)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'texts' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_inputs\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Check the lengths of sentences and labels\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (sentence, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mtexts\u001b[49m, labels)):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentence\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(label), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in length for sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m label_aligned_training_texts \u001b[38;5;241m=\u001b[39m align_labels(encoded_training_texts, encoded_training_labels)\n","\u001b[1;31mNameError\u001b[0m: name 'texts' is not defined"]}],"source":["def align_labels(tokenized_inputs, labels):\n","    aligned_labels = []\n","    obj_count = 0\n","    print(f\"Total batches: {len(tokenized_inputs)}\")\n","    print(labels)\n","    for i, label in enumerate(labels):\n","        print(f\"Tokenized Text {i+1}: {tokenizer.convert_ids_to_tokens(tokenized_inputs['input_ids'][i])}\")\n","        print(f\"Word IDs {i+1}: {tokenized_inputs.word_ids(batch_index=i)}\")\n","        print(f'Grabbing Label in position: {i}')\n","        label = labels[i]\n","        print(f'Label: {label}')\n","        obj_count += 1\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:\n","                print(f'Word idx: {word_idx}')\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        aligned_labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = torch.tensor(aligned_labels)\n","    return tokenized_inputs\n","\n","# Check the lengths of sentences and labels\n","\n","for idx, (sentence, label) in enumerate(zip(texts, labels)):\n","    assert len(sentence.split()) == len(label), f\"Mismatch in length for sentence {idx}\"\n","        \n","label_aligned_training_texts = align_labels(encoded_training_texts, encoded_training_labels)\n","label_aligned_validation_texts = align_labels(encoded_validation_texts, encoded_validation_labels)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_6740\\3518625147.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  training_dataset = TensorDataset(label_aligned_training_texts[\"input_ids\"], label_aligned_training_texts[\"attention_mask\"], torch.tensor(label_aligned_training_texts[\"labels\"]))\n","C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_6740\\3518625147.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  validation_dataset = TensorDataset(label_aligned_validation_texts[\"input_ids\"], label_aligned_validation_texts[\"attention_mask\"], torch.tensor(label_aligned_validation_texts[\"labels\"]))\n"]}],"source":["# we neeed to create Tensor datasets for \n","# our training and validation sets\n","training_dataset = TensorDataset(label_aligned_training_texts[\"input_ids\"], label_aligned_training_texts[\"attention_mask\"], torch.tensor(label_aligned_training_texts[\"labels\"]))\n","validation_dataset = TensorDataset(label_aligned_validation_texts[\"input_ids\"], label_aligned_validation_texts[\"attention_mask\"], torch.tensor(label_aligned_validation_texts[\"labels\"]))\n","\n","sampling_size = 10\n","training_loader = DataLoader(training_dataset, batch_size=sampling_size, shuffle=True)\n","validation_loader = DataLoader(validation_dataset, batch_size=sampling_size)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:40<00:00,  4.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.24465711279348892\n","Training Loss: 0.2447, Training Accuracy: 90.12%\n","Validation Loss: 0.0862, Validation Accuracy: 96.87%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:19<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 0.06298154341691936\n","Training Loss: 0.0630, Training Accuracy: 97.83%\n","Validation Loss: 0.0310, Validation Accuracy: 99.17%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:21<00:00,  3.69s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 0.044987000144002115\n","Training Loss: 0.0450, Training Accuracy: 98.24%\n","Validation Loss: 0.0329, Validation Accuracy: 98.83%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:17<00:00,  3.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 0.03342355812095444\n","Training Loss: 0.0334, Training Accuracy: 98.80%\n","Validation Loss: 0.0481, Validation Accuracy: 98.14%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:15<00:00,  3.42s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 0.022600980785103853\n","Training Loss: 0.0226, Training Accuracy: 99.35%\n","Validation Loss: 0.0175, Validation Accuracy: 99.65%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:15<00:00,  3.43s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 0.027629106427246534\n","Training Loss: 0.0276, Training Accuracy: 99.35%\n","Validation Loss: 0.0660, Validation Accuracy: 98.29%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:15<00:00,  3.44s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 0.03766054063188759\n","Training Loss: 0.0377, Training Accuracy: 98.74%\n","Validation Loss: 0.0260, Validation Accuracy: 98.97%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:15<00:00,  3.41s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 0.04729929656472946\n","Training Loss: 0.0473, Training Accuracy: 98.54%\n","Validation Loss: 0.0345, Validation Accuracy: 99.32%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:19<00:00,  3.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 0.03611942592992405\n","Training Loss: 0.0361, Training Accuracy: 98.78%\n","Validation Loss: 0.0533, Validation Accuracy: 97.88%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:13<00:00,  3.35s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.04531424050219357\n","Training Loss: 0.0453, Training Accuracy: 98.73%\n","Validation Loss: 0.0511, Validation Accuracy: 97.78%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:12<00:00,  3.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Loss: 0.023557949661732313\n","Training Loss: 0.0236, Training Accuracy: 99.16%\n","Validation Loss: 0.0124, Validation Accuracy: 99.49%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 22/22 [01:13<00:00,  3.33s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12, Loss: 0.029347881959190338\n","Training Loss: 0.0293, Training Accuracy: 98.93%\n","Validation Loss: 0.0126, Validation Accuracy: 99.14%\n"]}],"source":["def calculate_accuracy(logits, labels, ignore_index=-100):\n","    predictions = torch.argmax(logits, dim=2)\n","    mask = labels != ignore_index\n","    correct_predictions = (predictions == labels) & mask\n","    correct_predictions = correct_predictions.float()\n","    total_correct = correct_predictions.sum()\n","    total = mask.sum()\n","    accuracy = (total_correct / total) * 100\n","    return accuracy.item()\n","\n","def validation(avg_training_loss, avg_training_accuracy):\n","    model.eval()\n","    total_validation_loss = 0\n","    total_validation_accuracy = 0\n","    with torch.no_grad():\n","        for batch in validation_loader:\n","            \n","            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            \n","            total_validation_loss += loss.item()\n","            \n","            total_validation_accuracy += calculate_accuracy(outputs.logits, labels)\n","            \n","        avg_validation_loss = total_validation_loss / len(validation_loader)\n","        avg_validation_accuracy = total_validation_accuracy / len(validation_loader)\n","        \n","        print(f'Training Loss: {avg_training_loss:.4f}, Training Accuracy: {avg_training_accuracy:.2f}%')\n","        print(f'Validation Loss: {avg_validation_loss:.4f}, Validation Accuracy: {avg_validation_accuracy:.2f}%')\n","\n","        \n","\n","num_unique_labels = len(labels_to_index)\n","model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_unique_labels)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","print(f'Device: {device}')\n","# Define optimizer and training arguments\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n","\n","# Training loop\n","num_epochs = 12\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    total_accuracy = 0\n","    for batch in tqdm(training_loader):\n","        # we need to move our training batch to the same\n","        # hardware as the model\n","        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","        \n","        # We need to clear gradients from previous epochs\n","        optimizer.zero_grad()\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        total_accuracy += calculate_accuracy(outputs.logits, labels)\n","\n","    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(training_loader)}\")\n","    avg_training_loss = total_loss / len(training_loader)\n","    avg_training_accuracy = total_accuracy / len(training_loader)\n","    validation(avg_training_loss, avg_training_accuracy)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Example of using the prediction function\u001b[39;00m\n\u001b[0;32m     44\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m predicted_label, confidence \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Encode the input text\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Move the tensors to the same device as the model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m encoded_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"]}],"source":["# import this torch functional library and use softmax to convert\n","# logits to probabilites to get a confidence in a precentage\n","import torch.nn.functional as F\n","\n","# Function to take text input and pass to model\n","def predict(text):\n","    # Encode the input text\n","    encoded_input = tokenizer(text, padding='max_length', truncation=True, return_tensors=\"pt\")\n","\n","    # Move the tensors to the same device as the model\n","    input_ids = encoded_input[\"input_ids\"].to(device)\n","    attention_mask = encoded_input[\"attention_mask\"].to(device)\n","\n","    # Model inference\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","    # Get the logits and apply softmax to get probabilities\n","    logits = outputs.logits\n","\n","    predicted_token_class_ids = logits.argmax(-1)\n","\n","    # Decode the input ids back to tokens for display\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n","    print(tokens)\n","    # Collect predictions with their corresponding probabilities\n","    predictions = []\n","    predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n","    # Iterate over the tokens and their predicted token classes\n","    for token, token_class in zip(tokens, predicted_tokens_classes):\n","        label = [label for label, idx in labels_to_index.items() if idx == int(token_class[-1])]\n","        if label and label[0] != 'O':  # Assuming 'O' is the 'outside' label, typically ignored in display\n","            predictions.append((token, label[0]))\n","\n","    # Calculate average confidence if predictions are made\n","    if predictions:\n","        formatted_predictions = ', '.join([f\"{token}: {label}\" for token, label in predictions])\n","        confidence = calculate_accuracy(logits, labels)\n","        return formatted_predictions, confidence\n","    else:\n","        return \"No entities found.\", 0.0\n","\n","# Example of using the prediction function\n","prompt = input(\"Prompt: \")\n","predicted_label, confidence = predict(prompt)\n","print(f\"Predicted Label: {predicted_label}\\nConfidence: {confidence:.2f}%\")\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["torch.save(model, 'task_intent_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5008283,"sourceId":8414240,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
